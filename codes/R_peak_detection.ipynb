{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import load_patient, extract_training_windows, get_noise,normalize_bound\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#_______________________________________________\n",
    "# Initializations\n",
    "#_______________________________________________\n",
    "\n",
    "# Window/Segment length \n",
    "l = 20 #seconds\n",
    "# window stride for testing. \n",
    "s = 10 #seconds\n",
    "\n",
    "# Base folder path\n",
    "base_path = '../'\n",
    "\n",
    "training_data_path = base_path + 'training_data_aug/'\n",
    "\n",
    "#_______________________________________________\n",
    "# Dont change These Values\n",
    "#_______________________________________________\n",
    "# Sapmling frequency of ecg signal is 400 hz. (CPSC2020 Data)\n",
    "fs = 400\n",
    "# Window/Segment length in samples. \n",
    "win_size = l*fs\n",
    "# Stride for test window in samples. \n",
    "stride = s*fs\n",
    "#_______________________________________________\n",
    "\n",
    "if not os.path.exists(training_data_path):\n",
    "    os.makedirs(training_data_path)\n",
    "\n",
    "\n",
    "\n",
    "ma = np.load(base_path +'data/ma.npy')\n",
    "bw = np.load(base_path +'data/bw.npy')\n",
    "\n",
    "\n",
    "aug_factor = 1 # How many times to augment.\n",
    "\n",
    "\n",
    "\n",
    "for pat_num in range(1,11):\n",
    "\n",
    "\n",
    "    #_______________________________________________\n",
    "    # Training Data Preparation\n",
    "    #_______________________________________________\n",
    "    # Load 1 patient ecg and annotations\n",
    "    ecg, R_ann, S_ann, V_ann = load_patient(base_path, pat_num)\n",
    "    X_train, y_train, R_w, S_w, V_w = extract_training_windows(ecg, R_ann, S_ann, V_ann, win_size)\n",
    "\n",
    "    print('Total Windows : ', len(X_train))\n",
    "\n",
    "    # Indexes of windows where S beats are present.\n",
    "    s_w_idx = []\n",
    "    for idx,ann in enumerate(S_w):    \n",
    "        if ann.any():\n",
    "            s_w_idx.append(idx)\n",
    "    s_w_idx = np.asarray(s_w_idx, dtype=np.int32)\n",
    "\n",
    "\n",
    "    # Indexes of windows where V beats are present.\n",
    "    v_w_idx = []\n",
    "    for idx,ann in enumerate(V_w):    \n",
    "        if ann.any():\n",
    "            v_w_idx.append(idx)\n",
    "    v_w_idx = np.asarray(v_w_idx, dtype=np.int32)\n",
    "\n",
    "    # Indexes of windows for V beats and S beats combined.\n",
    "    sv_idx = np.unique(np.concatenate((s_w_idx,v_w_idx)))\n",
    "    # All indexes of training windows.\n",
    "    idx = np.arange(len(X_train))\n",
    "    # indexes other than S and V beats. (Normal R peaks)\n",
    "    rem_idx = np.delete(idx, sv_idx, 0)\n",
    "    \n",
    "    #_____________________________________________________________________\n",
    "    # Choose 50% of remaining. \n",
    "    #norm_idx = np.random.choice(rem_idx, size=int(len(rem_idx)*(1/2)), replace=False)\n",
    "    \n",
    "    norm_idx = rem_idx[::2]\n",
    "    \n",
    "    # Placeholder for augmented beats\n",
    "    X_aug = np.zeros((int(len(sv_idx)*aug_factor), win_size))\n",
    "    y_aug = np.zeros((int(len(sv_idx)*aug_factor), win_size))\n",
    "    \n",
    "    count = 0\n",
    "    for i in tqdm(range(len(sv_idx))):\n",
    "\n",
    "        current_window = X_train[sv_idx[i]]\n",
    "        current_window = np.squeeze(current_window)\n",
    "\n",
    "        for j in range(aug_factor):\n",
    "\n",
    "            noise = get_noise(ma, bw, win_size)\n",
    "            aug_window = current_window + noise\n",
    "\n",
    "            X_aug[count] = normalize_bound(aug_window, lb=-1, ub=1)\n",
    "\n",
    "            y_aug[count] = np.squeeze(y_train[sv_idx[i]])\n",
    "\n",
    "            count += 1\n",
    "            \n",
    "    X_aug = np.expand_dims(X_aug, axis=2)\n",
    "    y_aug = np.expand_dims(y_aug, axis=2)\n",
    "    \n",
    "    \n",
    "    #X_train = np.concatenate((X_train,X_aug))\n",
    "    #y_train = np.concatenate((y_train,y_aug))\n",
    "    \n",
    "    X_train = np.concatenate((X_train[norm_idx],X_train[sv_idx], X_aug))\n",
    "    y_train = np.concatenate((y_train[norm_idx],y_train[sv_idx], y_aug))\n",
    "\n",
    "\n",
    "    assert len(X_train) == len(y_train)\n",
    "\n",
    "    print('Normal Beat Windows : ', len(rem_idx))\n",
    "    print('Abnormal Beat Windows : ', len(sv_idx))\n",
    "    print('Augmented abnormal Beat Windows : ', len(X_aug))\n",
    "\n",
    "    print('Saving Data')\n",
    "    f_X = training_data_path+ 'X_train_P' + str(pat_num).zfill(2) + '.npy'\n",
    "    f_y = training_data_path+ 'y_train_P' + str(pat_num).zfill(2) + '.npy'\n",
    "    np.save(f_X, X_train)\n",
    "    np.save(f_y, y_train)\n",
    "    print('Done..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "Testing\n",
      "Patient:  1\n",
      "Q :  3\n",
      "******************************************\n",
      "______________________________________________\n",
      "Loading Data for Patient : 1\n",
      "______________________________________________\n",
      "Total Beats :  109731\n",
      "S beats :  24\n",
      "V beats :  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 110977/110977 [01:48<00:00, 1026.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109292\n",
      "______________________________________________\n",
      "All Beats\n",
      "______________________________________________\n",
      "_________Calculating Stats____________________\n",
      "______________________________________________\n",
      "TP's:108908 FN's:823 FP's:397\n",
      "Recall:99.25, Precision(FNR):99.64, F1-Score:99.44\n",
      "Total 109731\n",
      "______________________________________________\n",
      "S Beats\n",
      "______________________________________________\n",
      "_________Calculating Stats____________________\n",
      "______________________________________________\n",
      "TP's:24 FN's:0 FP's:96414\n",
      "Recall:100.0, Precision(FNR):0.02, F1-Score:0.04\n",
      "Total 24\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import train_selfONN, test_selfONN\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "Q = [3]\n",
    "all_patients = [1,2,3,4,5,6,7,8.9,10]\n",
    "base_path = '../'\n",
    "num_epochs = 30\n",
    "\n",
    "results_all = np.zeros((10*len(Q),6), dtype = np.int32)\n",
    "perc_all = np.zeros((10*len(Q),3), dtype = np.float32)\n",
    "results_S = np.zeros((10*len(Q),5), dtype = np.int32)\n",
    "results_V = np.zeros((10*len(Q),5), dtype = np.int32)\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "for pat_num in [1]:\n",
    "\n",
    "    for q in Q:\n",
    "        \n",
    "        \n",
    "        # Training\n",
    "        #train_selfONN(pat_num, q, epochs = num_epochs)\n",
    "        \n",
    "        # Testing\n",
    "        stats_R, stats_S, stats_V = test_selfONN(pat_num, q, threshold = 0.1)\n",
    "\n",
    "        #_______________________________________________\n",
    "        # Saving stats\n",
    "        #_______________________________________________\n",
    "\n",
    "        if not os.path.exists(base_path + 'Results'):\n",
    "            os.makedirs(base_path + 'Results')\n",
    "\n",
    "        # Save Results for All beats\n",
    "        results_all[count][0] = pat_num\n",
    "        results_all[count][1] = q\n",
    "        results_all[count][2:] = stats_R[:4]\n",
    "        perc_all[count] = stats_R[4:7]\n",
    "\n",
    "        df_all = pd.DataFrame(results_all)\n",
    "        df_all = pd.concat([df_all, pd.DataFrame(perc_all, dtype = np.float32)], axis=1)\n",
    "        df_all.columns = ['Patient No', 'Q', 'Total Beats', 'TP', 'FN', 'FP', 'Recall', 'Precision', 'F1']\n",
    "        f = base_path + 'Results/selfONN_all_3a.csv'\n",
    "        df_all.to_csv (r'{}'.format(f), index = False, header=True)\n",
    "\n",
    "        \n",
    "        # Save Results for S beats\n",
    "        if stats_S != []:\n",
    "            results_S[count][0] = pat_num\n",
    "            results_S[count][1] = q\n",
    "            results_S[count][2:] = stats_S[:3]\n",
    "\n",
    "            df_S = pd.DataFrame(results_S)\n",
    "            df_S.columns = ['Patient No', 'Q','Total Beats', 'Detected', 'Missed']\n",
    "            f = base_path + 'Results/selfONN_S_3a.csv'\n",
    "            df_S.to_csv (r'{}'.format(f), index = False, header=True)\n",
    "\n",
    "        # Save Results for V beats\n",
    "        if stats_V != []:\n",
    "\n",
    "            results_V[count][0] = pat_num\n",
    "            results_V[count][1] = q\n",
    "            results_V[count][2:] = stats_V[:3]\n",
    "\n",
    "            df_V = pd.DataFrame(results_V)\n",
    "            df_V.columns = ['Patient No', 'Q','Total Beats', 'Detected', 'Missed']\n",
    "            f = base_path + 'Results/selfONN_V_3a.csv'\n",
    "            df_V.to_csv (r'{}'.format(f), index = False, header=True)\n",
    "\n",
    "        count += 1 \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6ce3508e119d11a5597ec688043a166dd37850a4548418a299f7af683d14551"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
